{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting crypto arbitrage strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook, we will try to find the best crypto pair and the best exchange pair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#list the current work dir\n",
    "cwd = os.getcwd()\n",
    "current_path = Path(cwd)\n",
    "project_root = current_path.parent.parent\n",
    "\n",
    "#change the current work dir\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% Imports\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from bot.event_loop import EventLoop\n",
    "from broker.binance_fee_model import BinanceFeeModel\n",
    "from broker.broker_manager import BrokerManager\n",
    "from broker.kucoin_fee_model import KucoinFeeModel\n",
    "from broker.simulated_broker import SimulatedBroker\n",
    "from common.clock import SimulatedClock\n",
    "from feed.feed import CsvFeed, Feed, ExternalStorageFeed\n",
    "from indicators.indicators_manager import IndicatorsManager\n",
    "from models.asset import Asset\n",
    "from models.candle import Candle\n",
    "from models.enums import Action, Direction, OrderType\n",
    "from models.order import Order\n",
    "from order_manager.order_creator import OrderCreator\n",
    "from order_manager.order_manager import OrderManager\n",
    "from order_manager.position_sizer import PositionSizer\n",
    "from strategy.strategies.arbitrage_strategy import ArbitrageStrategy\n",
    "from market_data.historical.binance_historical_data_handler import BinanceHistoricalDataHandler\n",
    "from market_data.historical.kucoin_historical_data_handler import KucoinHistoricalDataHandler\n",
    "from common.helper import get_or_create_nested_dict\n",
    "from db_storage.mongodb_storage import MongoDbStorage\n",
    "from db_storage.influxdb_storage import InfluxDbStorage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%% Constants\n"
    }
   },
   "outputs": [],
   "source": [
    "BINANCE_EXCHANGE = \"BINANCE\"\n",
    "KUCOIN_EXCHANGE = \"KUCOIN\"\n",
    "EXCHANGES = [BINANCE_EXCHANGE, KUCOIN_EXCHANGE]\n",
    "DATA_HANDLERS = {\n",
    "    BINANCE_EXCHANGE: BinanceHistoricalDataHandler,\n",
    "    KUCOIN_EXCHANGE: KucoinHistoricalDataHandler\n",
    "}\n",
    "FEE_MODELS = {BINANCE_EXCHANGE: BinanceFeeModel(), KUCOIN_EXCHANGE: KucoinFeeModel()}\n",
    "seen = set()\n",
    "EXCHANGE_PAIRS = []\n",
    "for exchange1 in EXCHANGES:\n",
    "    for exchange2 in EXCHANGES:\n",
    "        if exchange2 in seen or exchange1 == exchange2:\n",
    "            continue\n",
    "        EXCHANGE_PAIRS.append((exchange1, exchange2))\n",
    "    seen.add(exchange1)\n",
    "LOOKBACK_PERIOD = timedelta(days=7)\n",
    "\n",
    "STABLE_COINS = [\"USDT\", \"USDC\", \"BUSD\", \"DAI\", \"UST\", \"TUSD\", \"PAX\", \"HUSD\", \"USDN\", \"GUSD\"]\n",
    "MINIMUM_TRANSACTIONS = 5\n",
    "MINIMUM_VOLUME_IN_CASH = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find common crypto pairs between exchange pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pairs_dict = {}\n",
    "for exchange_pair in EXCHANGE_PAIRS:\n",
    "    exchange1 = exchange_pair[0]\n",
    "    exchange2 = exchange_pair[1]\n",
    "    get_or_create_nested_dict(common_pairs_dict, exchange1, exchange2)\n",
    "    \n",
    "    exchange1_tickers_list = DATA_HANDLERS[exchange1].get_tickers_list()\n",
    "    exchange2_tickers_list = DATA_HANDLERS[exchange2].get_tickers_list()\n",
    "    \n",
    "    common_pairs = np.intersect1d(exchange1_tickers_list, exchange2_tickers_list)\n",
    "    \n",
    "    def ends_with_stable_coin(pair: str):\n",
    "        for stable_coin in STABLE_COINS:\n",
    "            if pair.endswith(stable_coin):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Consider only stable coin pairs for now\n",
    "    common_pairs = [common_pair for common_pair in common_pairs if ends_with_stable_coin(common_pair)]\n",
    "\n",
    "    common_pairs_dict[exchange1][exchange2] = common_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BINANCE': {'KUCOIN': ['1INCHUSDT',\n",
       "   'AAVEUSDT',\n",
       "   'ADAUSDC',\n",
       "   'ADAUSDT',\n",
       "   'AKROUSDT',\n",
       "   'ALGOUSDT',\n",
       "   'ANKRUSDT',\n",
       "   'ARPAUSDT',\n",
       "   'ATOMUSDT',\n",
       "   'AVAUSDT',\n",
       "   'AVAXUSDT',\n",
       "   'BATUSDT',\n",
       "   'BCHSVUSDC',\n",
       "   'BCHSVUSDT',\n",
       "   'BCHUSDC',\n",
       "   'BCHUSDT',\n",
       "   'BNBUSDT',\n",
       "   'BONDUSDT',\n",
       "   'BTCDAI',\n",
       "   'BTCPAX',\n",
       "   'BTCTUSD',\n",
       "   'BTCUSDC',\n",
       "   'BTCUSDT',\n",
       "   'BTTUSDT',\n",
       "   'CAKEUSDT',\n",
       "   'CELOUSDT',\n",
       "   'CHRUSDT',\n",
       "   'CHZUSDT',\n",
       "   'CKBUSDT',\n",
       "   'COMPUSDT',\n",
       "   'COTIUSDT',\n",
       "   'CRVUSDT',\n",
       "   'DASHUSDT',\n",
       "   'DEGOUSDT',\n",
       "   'DGBUSDT',\n",
       "   'DIAUSDT',\n",
       "   'DODOUSDT',\n",
       "   'DOGEUSDC',\n",
       "   'DOGEUSDT',\n",
       "   'DOTUSDT',\n",
       "   'ENJUSDT',\n",
       "   'EOSUSDC',\n",
       "   'EOSUSDT',\n",
       "   'ETCUSDT',\n",
       "   'ETHDAI',\n",
       "   'ETHPAX',\n",
       "   'ETHTUSD',\n",
       "   'ETHUSDC',\n",
       "   'ETHUSDT',\n",
       "   'FILUSDT',\n",
       "   'FORTHUSDT',\n",
       "   'FTMUSDT',\n",
       "   'GRTUSDT',\n",
       "   'ICPUSDT',\n",
       "   'IOSTUSDT',\n",
       "   'JSTUSDT',\n",
       "   'KSMUSDT',\n",
       "   'LINKUSDC',\n",
       "   'LINKUSDT',\n",
       "   'LPTUSDT',\n",
       "   'LRCUSDT',\n",
       "   'LTCUSDC',\n",
       "   'LTCUSDT',\n",
       "   'LUNAUSDT',\n",
       "   'MANAUSDT',\n",
       "   'MASKUSDT',\n",
       "   'MATICUSDT',\n",
       "   'MIRUSDT',\n",
       "   'MKRUSDT',\n",
       "   'NANOUSDT',\n",
       "   'NEARUSDT',\n",
       "   'NEOUSDT',\n",
       "   'OGNUSDT',\n",
       "   'OMGUSDT',\n",
       "   'ONEUSDT',\n",
       "   'ONTUSDT',\n",
       "   'ORNUSDT',\n",
       "   'PHAUSDT',\n",
       "   'POLSUSDT',\n",
       "   'PUNDIXUSDT',\n",
       "   'RENUSDT',\n",
       "   'ROSEUSDT',\n",
       "   'SANDUSDT',\n",
       "   'SHIBUSDT',\n",
       "   'SNXUSDT',\n",
       "   'STMXUSDT',\n",
       "   'STXUSDT',\n",
       "   'SUNUSDT',\n",
       "   'SUSDUSDT',\n",
       "   'SUSHIUSDT',\n",
       "   'SXPUSDT',\n",
       "   'THETAUSDT',\n",
       "   'TOMOUSDT',\n",
       "   'TRXUSDT',\n",
       "   'UMAUSDT',\n",
       "   'UNFIUSDT',\n",
       "   'UNIUSDT',\n",
       "   'USDCUSDT',\n",
       "   'USDTDAI',\n",
       "   'VETUSDT',\n",
       "   'WAVESUSDT',\n",
       "   'WINUSDT',\n",
       "   'XEMUSDT',\n",
       "   'XLMUSDT',\n",
       "   'XMRUSDT',\n",
       "   'XRPPAX',\n",
       "   'XRPTUSD',\n",
       "   'XRPUSDC',\n",
       "   'XRPUSDT',\n",
       "   'XTZUSDT',\n",
       "   'YFIUSDT',\n",
       "   'ZECUSDT',\n",
       "   'ZENUSDT',\n",
       "   'ZILUSDT']}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_pairs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data for the last lookback period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now(timezone.utc)\n",
    "start = end - LOOKBACK_PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 2 / 228\n",
      "Progress: 4 / 228\n",
      "Progress: 6 / 228\n",
      "Progress: 8 / 228\n",
      "Progress: 10 / 228\n",
      "Progress: 12 / 228\n",
      "Progress: 14 / 228\n",
      "Progress: 16 / 228\n",
      "Progress: 18 / 228\n",
      "Progress: 20 / 228\n",
      "Progress: 22 / 228\n",
      "Progress: 24 / 228\n",
      "Progress: 26 / 228\n",
      "Progress: 28 / 228\n",
      "Progress: 30 / 228\n",
      "Progress: 32 / 228\n",
      "Progress: 34 / 228\n",
      "Progress: 36 / 228\n",
      "Progress: 38 / 228\n",
      "Progress: 40 / 228\n",
      "Progress: 42 / 228\n",
      "Progress: 44 / 228\n",
      "Progress: 46 / 228\n",
      "Progress: 48 / 228\n",
      "Progress: 50 / 228\n",
      "Progress: 52 / 228\n",
      "Progress: 54 / 228\n",
      "Progress: 56 / 228\n",
      "Progress: 58 / 228\n",
      "Progress: 60 / 228\n",
      "Progress: 62 / 228\n",
      "Progress: 64 / 228\n",
      "Progress: 66 / 228\n",
      "Progress: 68 / 228\n",
      "Progress: 70 / 228\n",
      "Progress: 72 / 228\n",
      "Progress: 74 / 228\n",
      "Progress: 76 / 228\n",
      "Progress: 78 / 228\n",
      "Progress: 80 / 228\n",
      "Progress: 82 / 228\n",
      "Progress: 84 / 228\n",
      "Progress: 86 / 228\n",
      "Progress: 88 / 228\n",
      "Progress: 90 / 228\n",
      "Progress: 92 / 228\n",
      "Progress: 94 / 228\n",
      "Progress: 96 / 228\n",
      "Progress: 98 / 228\n",
      "Progress: 100 / 228\n",
      "Progress: 102 / 228\n",
      "Progress: 104 / 228\n",
      "Progress: 106 / 228\n",
      "Progress: 108 / 228\n",
      "Progress: 110 / 228\n",
      "Progress: 112 / 228\n",
      "Progress: 114 / 228\n",
      "Progress: 116 / 228\n",
      "Progress: 118 / 228\n",
      "Progress: 120 / 228\n",
      "Progress: 122 / 228\n",
      "Progress: 124 / 228\n",
      "Progress: 126 / 228\n",
      "Progress: 128 / 228\n",
      "Progress: 130 / 228\n",
      "Progress: 132 / 228\n",
      "Progress: 134 / 228\n",
      "Progress: 136 / 228\n",
      "Progress: 138 / 228\n",
      "Progress: 140 / 228\n",
      "Progress: 142 / 228\n",
      "Progress: 144 / 228\n",
      "Progress: 146 / 228\n",
      "Progress: 148 / 228\n",
      "Progress: 150 / 228\n",
      "Progress: 152 / 228\n",
      "Progress: 154 / 228\n",
      "Progress: 156 / 228\n",
      "Progress: 158 / 228\n",
      "Progress: 160 / 228\n",
      "Progress: 162 / 228\n",
      "Progress: 164 / 228\n",
      "Progress: 166 / 228\n",
      "Progress: 168 / 228\n",
      "Progress: 170 / 228\n",
      "Progress: 172 / 228\n",
      "Progress: 174 / 228\n",
      "Progress: 176 / 228\n",
      "Progress: 178 / 228\n",
      "Progress: 180 / 228\n",
      "Progress: 182 / 228\n",
      "Progress: 184 / 228\n",
      "Progress: 186 / 228\n",
      "Progress: 188 / 228\n",
      "Progress: 190 / 228\n",
      "Progress: 192 / 228\n",
      "Progress: 194 / 228\n",
      "Progress: 196 / 228\n",
      "Progress: 198 / 228\n",
      "Progress: 200 / 228\n",
      "Progress: 202 / 228\n",
      "Progress: 204 / 228\n",
      "Progress: 206 / 228\n",
      "Progress: 208 / 228\n",
      "Progress: 210 / 228\n",
      "Progress: 212 / 228\n",
      "Progress: 214 / 228\n",
      "Progress: 216 / 228\n",
      "Progress: 218 / 228\n",
      "Progress: 220 / 228\n",
      "Progress: 222 / 228\n",
      "Progress: 224 / 228\n",
      "Progress: 226 / 228\n",
      "Progress: 228 / 228\n"
     ]
    }
   ],
   "source": [
    "db_storage = InfluxDbStorage()\n",
    "for exchange_pair in EXCHANGE_PAIRS:\n",
    "    exchange1 = exchange_pair[0]\n",
    "    exchange2 = exchange_pair[1]\n",
    "\n",
    "    common_pairs = common_pairs_dict[exchange1][exchange2]\n",
    "    downloaded = 0\n",
    "    to_download = 2 * len(common_pairs)\n",
    "    for common_pair in common_pairs:\n",
    "        exchange1_asset = Asset(symbol=common_pair, exchange=exchange1)\n",
    "        DATA_HANDLERS[exchange1].save_ticker_data_in_db_storage(\n",
    "            exchange1_asset, db_storage, start, end\n",
    "        )\n",
    "\n",
    "        exchange2_asset = Asset(symbol=common_pair, exchange=exchange2)\n",
    "        DATA_HANDLERS[exchange2].save_ticker_data_in_db_storage(\n",
    "            exchange2_asset, db_storage, start, end\n",
    "        )\n",
    "        downloaded += 2\n",
    "        print(f\"Progress: {downloaded} / {to_download}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking arbitrage opportunities for BINANCE and KUCOIN exchange pair\n",
      "Checking arbitrage opportunities for BTCDAI\n",
      "BINANCE_KUCOIN_BTCDAI volume in cash 0.0 is lower than the minimum volume in cash required 1000 so it is skipped.\n",
      "Current rank: {}\n",
      "Progress: 1 / 15\n",
      "Checking arbitrage opportunities for XMRUSDT\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b818562c188b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mdb_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mfile_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mmarket_cal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         )\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/feed/feed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, assets, events, time_unit, start, end, db_storage, file_storage, market_cal)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mmarket_cal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarket_cal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mexternal_storage_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandle_dataframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_storage_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandle_dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mcandles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexternal_storage_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/feed/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0masset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             self.candle_dataframes[asset] = self.candle_fetcher.fetch(\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0masset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             )\n\u001b[1;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandle_dataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_candles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/strategy/candlefetcher.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, symbol, time_unit, start, end)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mmarket_cal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample_candle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarket_cal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/common/helper.py\u001b[0m in \u001b[0;36mresample_candle_data\u001b[0;34m(candle_dataframe, time_unit, market_cal_df)\u001b[0m\n\u001b[1;32m    242\u001b[0m ) -> CandleDataFrame:\n\u001b[1;32m    243\u001b[0m     \u001b[0masset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandle_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mcandle_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_missing_datetimes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcandle_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_unit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0mcandle_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCandleDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandle_dataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/common/helper.py\u001b[0m in \u001b[0;36mfill_missing_datetimes\u001b[0;34m(df, time_unit)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;34m\"low\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;34m\"close\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;34m\"volume\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         }\n\u001b[1;32m    225\u001b[0m     )\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_binner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_agg_1dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_agg\u001b[0;34m(arg, func)\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_how\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magg_how\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_agg_1dim\u001b[0;34m(name, how, subset)\u001b[0m\n\u001b[1;32m    365\u001b[0m                         \u001b[0;34m\"nested dictionary is ambiguous in aggregation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                     )\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcolg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m_agg_2dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mcyfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcyfunc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcyfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnkeys\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m         return self._agg_general(\n\u001b[0;32m-> 1554\u001b[0;31m             \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m         )\n\u001b[1;32m   1556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_agg_general\u001b[0;34m(self, numeric_only, min_count, alias, npfunc)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;31m# apply a non-cython aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"groupby\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                 return self._python_agg_general(\n\u001b[0;32m--> 261\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m                 )\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_agg_general\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                     \u001b[0;31m# if this function is invalid for this dtype, we will ignore it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36magg_series\u001b[0;34m(self, obj, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mdummy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mgrouper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeriesBinGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.SeriesBinGrouper.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction._BaseGrouper._apply_to_group\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_builtin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"numba\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;31m# iterate through \"columns\" ex exclusions to populate output dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;31m# apply a non-cython aggregation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"groupby\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2829\u001b[0m     \"\"\"\n\u001b[1;32m   2830\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0;32m-> 2831\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11473\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11474\u001b[0m         return self._reduce(\n\u001b[0;32m> 11475\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11476\u001b[0m         )\n\u001b[1;32m  11477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4247\u001b[0m                 )\n\u001b[1;32m   4248\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4249\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mreduction\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         values, mask, dtype, dtype_max, fill_value = _get_values(\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value_typ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(values, skipna, fill_value, fill_value_typ, mask)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mskipna\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google_Drive/Projects/MInvest/Trazy/trazy_analysis/env/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_any\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "initial_budget = 2000\n",
    "errors_pct_dict = {}\n",
    "profit_pct_dict = {}\n",
    "profit_pct_corrected_dict = {}\n",
    "profit_rank = {}\n",
    "\n",
    "\n",
    "for exchange_pair in EXCHANGE_PAIRS:\n",
    "    exchange1 = exchange_pair[0]\n",
    "    exchange2 = exchange_pair[1]\n",
    "    exchanges = [exchange1, exchange2]\n",
    "    print(f\"Checking arbitrage opportunities for {exchange1} and {exchange2} exchange pair\")\n",
    "    \n",
    "    common_pairs = common_pairs_dict[exchange1][exchange2]\n",
    "    common_pairs = [\n",
    "     'BTCDAI',\n",
    "     'XMRUSDT',\n",
    "     'ENJUSDT',\n",
    "     'ETHDAI',\n",
    "     'SNXUSDT',\n",
    "     'ETHTUSD',\n",
    "     'MIRUSDT',\n",
    "     'COMPUSDT',\n",
    "     'BONDUSDT',\n",
    "     '1INCHUSDT',\n",
    "     'BTCTUSD',\n",
    "     'ZENUSDT',\n",
    "     'WAVESUSDT',\n",
    "     'FORTHUSDT',\n",
    "     'NANOUSDT'\n",
    "    ]\n",
    "    to_process = len(common_pairs)\n",
    "    processed = 0\n",
    "    for common_pair in common_pairs:\n",
    "        common_pair_key = f\"{exchange1}_{exchange2}_{common_pair}\"\n",
    "        print(f\"Checking arbitrage opportunities for {common_pair}\")\n",
    "        events = deque()\n",
    "        assets = [Asset(symbol=common_pair, exchange=exchange) for exchange in exchanges]\n",
    "        assets_dict = {asset.exchange: asset for asset in assets}\n",
    "\n",
    "        # load data\n",
    "        #feed: Feed = CsvFeed(\n",
    "        #    {\n",
    "        #        asset: f\"backtests/crypto_arbitrage/data/{common_pair.lower()}_{asset.exchange.lower()}.csv\"\n",
    "        #        for asset in assets\n",
    "        #    },\n",
    "        #    events,\n",
    "        #)\n",
    "        \n",
    "        feed: Feed = ExternalStorageFeed(\n",
    "            assets = assets,\n",
    "            events = events,\n",
    "            time_unit = timedelta(minutes=1),\n",
    "            start = start,\n",
    "            end = end,\n",
    "            db_storage = db_storage,\n",
    "            file_storage = None,\n",
    "            market_cal = None,\n",
    "        )\n",
    "            \n",
    "        # Check wether data is empty or not\n",
    "        exchange1_candle_dataframe = feed.candle_dataframes[\n",
    "            assets_dict[exchange1]\n",
    "        ]\n",
    "        exchange2_candle_dataframe = feed.candle_dataframes[\n",
    "            assets_dict[exchange2]\n",
    "        ]\n",
    "        \n",
    "        if exchange1_candle_dataframe.empty or exchange2_candle_dataframe.empty:\n",
    "            processed += 1\n",
    "            print(f\"{common_pair_key} data is empty for at least one of the exchange so it is skipped.\")\n",
    "            print(f\"Current rank: {profit_rank}\")\n",
    "            print(f\"Progress: {processed} / {to_process}\")\n",
    "            continue\n",
    "        \n",
    "        # don't process the pair if the volume is low\n",
    "        exchange1_prices = pd.to_numeric(exchange1_candle_dataframe[\"close\"])\n",
    "        exchange1_volumes = pd.to_numeric(exchange1_candle_dataframe[\"volume\"])\n",
    "        exchange1_avg_price = exchange1_prices.median()\n",
    "        print(f\"price = {exchange1_avg_price}\")\n",
    "        exchange1_avg_volume = exchange1_volumes.median()\n",
    "        print(f\"volume = {exchange1_avg_volume}\")\n",
    "\n",
    "        exchange2_prices = pd.to_numeric(exchange2_candle_dataframe[\"close\"])\n",
    "        exchange2_volumes = pd.to_numeric(exchange2_candle_dataframe[\"volume\"])\n",
    "        exchange2_avg_price = exchange2_prices.median()\n",
    "        exchange2_avg_volume = exchange2_volumes.median()\n",
    "        \n",
    "        price = min(exchange1_avg_price, exchange2_avg_price)\n",
    "        volume = min(exchange1_avg_volume, exchange2_avg_volume)\n",
    "        \n",
    "        volume_in_cash = volume * price\n",
    "        \n",
    "        if volume_in_cash < MINIMUM_VOLUME_IN_CASH:\n",
    "            processed += 1\n",
    "            print(f\"{common_pair_key} volume in cash {volume_in_cash} is lower than the minimum volume in cash required {MINIMUM_VOLUME_IN_CASH} so it is skipped.\")\n",
    "            print(f\"Current rank: {profit_rank}\")\n",
    "            print(f\"Progress: {processed} / {to_process}\")\n",
    "            continue\n",
    "            \n",
    "        # Create brokers for exchanges, put a big amount of cash and a big amount of shares to allow all two\n",
    "        # ways transactions\n",
    "        strategies = {ArbitrageStrategy: [{\"margin_factor\": 2}]}\n",
    "        \n",
    "        clock = SimulatedClock()\n",
    "        initial_funds = initial_budget / 2\n",
    "        # print(f\"initial_funds = {initial_funds}\")\n",
    "        # Create brokers with a big amount of money\n",
    "        exchange1_broker = SimulatedBroker(\n",
    "            clock,\n",
    "            events,\n",
    "            initial_funds=initial_funds,\n",
    "            fee_model=FEE_MODELS[exchange1],\n",
    "            exchange=exchange1,\n",
    "        )\n",
    "        exchange1_broker.subscribe_funds_to_portfolio(initial_funds)\n",
    "        exchange1_first_candle = exchange1_candle_dataframe.get_candle(0)\n",
    "        exchange1_broker.update_price(exchange1_first_candle)\n",
    "\n",
    "        exchange2_broker = SimulatedBroker(\n",
    "            clock,\n",
    "            events,\n",
    "            initial_funds=initial_funds,\n",
    "            fee_model=FEE_MODELS[exchange2],\n",
    "            exchange=exchange2,\n",
    "        )\n",
    "        # exchange2_broker.subscribe_funds_to_portfolio(initial_funds)\n",
    "        exchange2_first_candle = exchange2_candle_dataframe.get_candle(0)\n",
    "        exchange2_broker.update_price(exchange2_first_candle)\n",
    "        max_size_exchange1 = exchange1_broker.max_entry_order_size(\n",
    "            assets_dict[exchange1], Direction.LONG, initial_funds\n",
    "        )\n",
    "        max_size_exchange2 = exchange2_broker.max_entry_order_size(\n",
    "            assets_dict[exchange2], Direction.LONG, initial_funds\n",
    "        )\n",
    "        initial_size = max_size_exchange2\n",
    "        \n",
    "        # exchange 2\n",
    "        candle = Candle(\n",
    "            asset=assets_dict[exchange2], open=0, high=0, low=0, close=0, volume=0\n",
    "        )\n",
    "        exchange2_broker.update_price(candle)\n",
    "        order = Order(\n",
    "            asset=assets_dict[exchange2],\n",
    "            action=Action.BUY,\n",
    "            direction=Direction.LONG,\n",
    "            size=initial_size,\n",
    "            signal_id=\"0\",\n",
    "            limit=None,\n",
    "            stop=None,\n",
    "            target=None,\n",
    "            stop_pct=None,\n",
    "            type=OrderType.MARKET,\n",
    "            clock=clock,\n",
    "            time_in_force=timedelta(minutes=5),\n",
    "        )\n",
    "        exchange2_broker.execute_market_order(order)\n",
    "        \n",
    "        # prepare event loop parameters\n",
    "        broker_manager = BrokerManager(\n",
    "            brokers={\n",
    "                exchange1: exchange1_broker,\n",
    "                exchange2: exchange2_broker,\n",
    "            },\n",
    "            clock=clock,\n",
    "        )\n",
    "        position_sizer = PositionSizer(broker_manager=broker_manager, integer_size=False)\n",
    "        order_creator = OrderCreator(broker_manager=broker_manager)\n",
    "        order_manager = OrderManager(\n",
    "            events=events,\n",
    "            broker_manager=broker_manager,\n",
    "            position_sizer=position_sizer,\n",
    "            order_creator=order_creator,\n",
    "        )\n",
    "        indicators_manager = IndicatorsManager(\n",
    "            preload=True, initial_data=feed.candles\n",
    "        )\n",
    "        event_loop = EventLoop(\n",
    "            events=events,\n",
    "            assets=assets,\n",
    "            feed=feed,\n",
    "            order_manager=order_manager,\n",
    "            strategies_parameters=strategies,\n",
    "            indicators_manager=indicators_manager,\n",
    "            close_at_end_of_day=False,\n",
    "            close_at_end_of_data=False\n",
    "        )\n",
    "\n",
    "        # get initial state of portfolio for stats computation total_market_value\n",
    "        exchange1_broker.update_price(exchange1_first_candle)\n",
    "        exchange2_broker.update_price(exchange2_first_candle)\n",
    "        initial_market_values = sum([broker_manager.get_broker(exchange).get_portfolio_total_market_value() for exchange in exchanges])\n",
    "        initial_cash_balances = sum([broker_manager.get_broker(exchange).get_portfolio_cash_balance() for exchange in exchanges])\n",
    "        initial_equities = initial_cash_balances + initial_market_values\n",
    "        \n",
    "        # print(f\"initial_market_values = {initial_market_values}\")\n",
    "        # print(f\"initial_cash_balances = {initial_cash_balances}\")\n",
    "        # print(f\"initial_equities = {initial_equities}\")\n",
    "\n",
    "        event_loop.loop()\n",
    "        \n",
    "        exchange1_history = exchange1_broker.portfolio.history\n",
    "        exchange1_transactions = [portfolio_event for portfolio_event in exchange1_history if portfolio_event.type == \"symbol_transaction\"]\n",
    "        # remove first transaction, which is to add securities in the broker\n",
    "        exchange1_transactions = exchange1_transactions[1:]\n",
    "\n",
    "        exchange2_history = exchange2_broker.portfolio.history\n",
    "        exchange2_transactions = [portfolio_event for portfolio_event in exchange2_history if portfolio_event.type == \"symbol_transaction\"]\n",
    "        # remove first transaction, which is to add securities in the broker\n",
    "        exchange2_transactions = exchange2_transactions[1:]\n",
    "        \n",
    "        # exchange1_transactions_timestamps = np.array([transaction.timestamp for transaction in exchange1_transactions], dtype=datetime)\n",
    "        # exchange2_transactions_timestamps = np.array([transaction.timestamp for transaction in exchange2_transactions], dtype=datetime)\n",
    "        # common_timestamps = np.intersect1d(exchange1_transactions_timestamps, exchange2_transactions_timestamps)\n",
    "        \n",
    "        # filter timestamps\n",
    "        # exchange1_transactions = [transaction for transaction in exchange1_transactions if transaction.timestamp in common_timestamps]\n",
    "        # exchange2_transactions = [transaction for transaction in exchange2_transactions if transaction.timestamp in common_timestamps]\n",
    "        \n",
    "        nb_transactions1 = len(exchange1_transactions)\n",
    "        nb_transactions2 = len(exchange2_transactions)\n",
    "        min_nb_transactions = min(nb_transactions1, nb_transactions2)      \n",
    "        if len(exchange1_transactions) < MINIMUM_TRANSACTIONS:\n",
    "            processed += 1\n",
    "            print(f\"{common_pair_key} has only {min_nb_transactions} transactions which is less than the minimum required number of transactions {MINIMUM_TRANSACTIONS} so it is skipped.\")\n",
    "            print(f\"Current rank: {profit_rank}\")\n",
    "            print(f\"Progress: {processed} / {to_process}\")\n",
    "            continue\n",
    "        \n",
    "        # find missed opportunities\n",
    "        \n",
    "        \"\"\"\n",
    "        When an arbitrage opportunity is found, we submit 2 orders to the brokers of the 2 exchanges.\n",
    "        If one of the order is not executed because of for example not enough cash or, whathever reason,\n",
    "        we call it an \"error\". The less errors you have, the better it is for ensuring the stability of the strategy\n",
    "        \"\"\"\n",
    "        nb_errors = 0\n",
    "        transaction_profits = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        while i < nb_transactions1 and j < nb_transactions2:\n",
    "            transaction1 = exchange1_transactions[i]\n",
    "            transaction2 = exchange2_transactions[j]\n",
    "            if transaction1.timestamp == transaction2.timestamp:\n",
    "                i += 1\n",
    "                j += 1\n",
    "            elif transaction1.timestamp < transaction2.timestamp:\n",
    "                i += 1\n",
    "                nb_errors += 1\n",
    "                continue\n",
    "            else: # transaction1.timestamp > transaction2.timestamp\n",
    "                j += 1\n",
    "                nb_errors += 1\n",
    "                continue\n",
    "            if transaction1.action == Action.BUY:\n",
    "                transaction_profit = transaction2.credit - transaction1.debit\n",
    "            else:\n",
    "                transaction_profit = transaction1.credit - transaction2.debit\n",
    "            # print(f\"{transaction1.timestamp} - profit = {transaction_profit}\")\n",
    "            transaction_profits.append(transaction_profit)\n",
    "        \n",
    "        if nb_errors > min_nb_transactions:\n",
    "            processed += 1\n",
    "            print(f\"{common_pair_key} nb errors is greater than number of transactions {min_nb_transactions} transactions so it is skipped.\")\n",
    "            print(f\"Current rank: {profit_rank}\")\n",
    "            print(f\"Progress: {processed} / {to_process}\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        errors_pct = nb_errors / max(nb_transactions1, nb_transactions2) * 100\n",
    "        cash_profit = sum(transaction_profits)\n",
    "        print(f\"cash_profit = {cash_profit}\")\n",
    "\n",
    "        # let's find the coefficient of variation to filter\n",
    "        cv = lambda x: np.std(x, ddof=1) / np.mean(x) * 100 \n",
    "        coefficient_of_variation = cv(transaction_profits)\n",
    "        \n",
    "        get_or_create_nested_dict(errors_pct_dict, common_pair_key)\n",
    "        errors_pct_dict[common_pair_key] = errors_pct\n",
    "        \n",
    "        final_market_values = sum([broker_manager.get_broker(exchange).get_portfolio_total_market_value() for exchange in exchanges])\n",
    "        final_cash_balances = sum([broker_manager.get_broker(exchange).get_portfolio_cash_balance() for exchange in exchanges])\n",
    "        final_equities = final_market_values + final_cash_balances\n",
    "\n",
    "        # print(f\"final_market_values = {final_market_values}\")\n",
    "        # print(f\"final_cash_balances = {final_cash_balances}\")\n",
    "        # print(f\"final_equities = {final_equities}\")\n",
    "\n",
    "        profit = final_equities - initial_equities\n",
    "\n",
    "        profit_pct = profit / initial_equities * 100\n",
    "        \n",
    "        cash_profit_pct = cash_profit / initial_cash_balances * 100\n",
    "\n",
    "        get_or_create_nested_dict(profit_pct_dict, common_pair_key)\n",
    "        profit_pct_dict[common_pair_key] = {\n",
    "            \"profit_pct\": profit_pct,\n",
    "            \"cash_profit_pct\": cash_profit_pct,\n",
    "            \"coefficient of varition (abs)\": abs(coefficient_of_variation),\n",
    "            \"nb_errors\": nb_errors,\n",
    "            \"errors_pct\": errors_pct,\n",
    "            \"minimum number of transactions in both exchanges\": min_nb_transactions\n",
    "        }\n",
    "        \n",
    "        # exchange1_broker.portfolio.history_to_df().to_csv(f\"backtests/crypto_arbitrage/data/transactions/{common_pair.lower()}_{exchange1.lower()}_transactions.csv\")\n",
    "        # exchange2_broker.portfolio.history_to_df().to_csv(f\"backtests/crypto_arbitrage/data/transactions/{common_pair.lower()}_{exchange2.lower()}_transactions.csv\")\n",
    "        \n",
    "        processed += 1\n",
    "        print(f\"{common_pair_key} profit: {profit_pct}\")\n",
    "        \n",
    "        # Order by number of errors\n",
    "        profit_rank = {k: v for k, v in sorted(profit_pct_dict.items(), key=lambda item: item[1][\"coefficient of varition (abs)\"], reverse=False)}\n",
    "        print(f\"Current rank: {profit_rank}\")\n",
    "        print(f\"Progress: {processed} / {to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df = pd.DataFrame.from_dict(profit_rank, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTCDAI',\n",
       " 'XMRUSDT',\n",
       " 'ENJUSDT',\n",
       " 'ETHDAI',\n",
       " 'SNXUSDT',\n",
       " 'ETHTUSD',\n",
       " 'MIRUSDT',\n",
       " 'COMPUSDT',\n",
       " 'BONDUSDT',\n",
       " '1INCHUSDT',\n",
       " 'BTCTUSD',\n",
       " 'ZENUSDT',\n",
       " 'WAVESUSDT',\n",
       " 'FORTHUSDT',\n",
       " 'NANOUSDT']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = list(best_results_df.index)\n",
    "m = [i[15:] for i in l]\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>profit_pct</th>\n",
       "      <th>cash_profit_pct</th>\n",
       "      <th>coefficient of varition (abs)</th>\n",
       "      <th>nb_errors</th>\n",
       "      <th>minimum number of transactions in both exchanges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profit_pct</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100477</td>\n",
       "      <td>-0.261412</td>\n",
       "      <td>0.406786</td>\n",
       "      <td>0.279019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cash_profit_pct</th>\n",
       "      <td>0.100477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.118749</td>\n",
       "      <td>0.350913</td>\n",
       "      <td>0.931028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coefficient of varition (abs)</th>\n",
       "      <td>-0.261412</td>\n",
       "      <td>-0.118749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.335351</td>\n",
       "      <td>0.051262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_errors</th>\n",
       "      <td>0.406786</td>\n",
       "      <td>0.350913</td>\n",
       "      <td>0.335351</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.631731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum number of transactions in both exchanges</th>\n",
       "      <td>0.279019</td>\n",
       "      <td>0.931028</td>\n",
       "      <td>0.051262</td>\n",
       "      <td>0.631731</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  profit_pct  cash_profit_pct  \\\n",
       "profit_pct                                          1.000000         0.100477   \n",
       "cash_profit_pct                                     0.100477         1.000000   \n",
       "coefficient of varition (abs)                      -0.261412        -0.118749   \n",
       "nb_errors                                           0.406786         0.350913   \n",
       "minimum number of transactions in both exchanges    0.279019         0.931028   \n",
       "\n",
       "                                                  coefficient of varition (abs)  \\\n",
       "profit_pct                                                            -0.261412   \n",
       "cash_profit_pct                                                       -0.118749   \n",
       "coefficient of varition (abs)                                          1.000000   \n",
       "nb_errors                                                              0.335351   \n",
       "minimum number of transactions in both exchanges                       0.051262   \n",
       "\n",
       "                                                  nb_errors  \\\n",
       "profit_pct                                         0.406786   \n",
       "cash_profit_pct                                    0.350913   \n",
       "coefficient of varition (abs)                      0.335351   \n",
       "nb_errors                                          1.000000   \n",
       "minimum number of transactions in both exchanges   0.631731   \n",
       "\n",
       "                                                  minimum number of transactions in both exchanges  \n",
       "profit_pct                                                                                0.279019  \n",
       "cash_profit_pct                                                                           0.931028  \n",
       "coefficient of varition (abs)                                                             0.051262  \n",
       "nb_errors                                                                                 0.631731  \n",
       "minimum number of transactions in both exchanges                                          1.000000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results_df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
