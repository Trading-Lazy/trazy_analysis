{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting crypto arbitrage strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "In this notebook, we will try to find the best crypto pair and the best exchange pair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "#list the current work dir\n",
    "cwd = os.getcwd()\n",
    "current_path = Path(cwd)\n",
    "project_root = current_path.parent.parent.parent\n",
    "\n",
    "#change the current work dir\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% Imports\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "from trazy_analysis.bot.event_loop import EventLoop\n",
    "from trazy_analysis.broker.binance_fee_model import BinanceFeeModel\n",
    "from trazy_analysis.broker.broker_manager import BrokerManager\n",
    "from trazy_analysis.broker.kucoin_fee_model import KucoinFeeModel\n",
    "from trazy_analysis.broker.percent_fee_model import PercentFeeModel\n",
    "from trazy_analysis.broker.simulated_broker import SimulatedBroker\n",
    "from trazy_analysis.common.clock import SimulatedClock\n",
    "from trazy_analysis.common.ccxt_connector import CcxtConnector\n",
    "from trazy_analysis.feed.feed import CsvFeed, Feed, ExternalStorageFeed\n",
    "from trazy_analysis.indicators.indicators_manager import IndicatorsManager\n",
    "from trazy_analysis.models.asset import Asset\n",
    "from trazy_analysis.models.candle import Candle\n",
    "from trazy_analysis.models.enums import Action, Direction, OrderType\n",
    "from trazy_analysis.models.order import Order\n",
    "from trazy_analysis.order_manager.order_creator import OrderCreator\n",
    "from trazy_analysis.order_manager.order_manager import OrderManager\n",
    "from trazy_analysis.order_manager.position_sizer import PositionSizer\n",
    "from trazy_analysis.strategy.strategies.arbitrage_strategy import ArbitrageStrategy\n",
    "from trazy_analysis.market_data.historical.binance_historical_data_handler import BinanceHistoricalDataHandler\n",
    "from trazy_analysis.market_data.historical.kucoin_historical_data_handler import KucoinHistoricalDataHandler\n",
    "from trazy_analysis.market_data.historical.ccxt_historical_data_handler import CcxtHistoricalDataHandler\n",
    "from trazy_analysis.common.helper import get_or_create_nested_dict\n",
    "from trazy_analysis.db_storage.mongodb_storage import MongoDbStorage\n",
    "from trazy_analysis.db_storage.influxdb_storage import InfluxDbStorage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ccxt\n",
    "import re\n",
    "import multiprocessing\n",
    "import pytz\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mongo_db_storage = MongoDbStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mongo_db_storage.get_state(\"ccxt_avalaible_exchanges\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of exchanges and create api_keys\n",
    "blacklisted = set()#{\"bitbay\"}\n",
    "exchanges = ccxt.exchanges\n",
    "exchanges = [exchange for exchange in exchanges if exchange not in blacklisted]\n",
    "exchanges_api_keys = {\n",
    "    exchange: {\n",
    "        \"key\": None,\n",
    "        \"secret\": None,\n",
    "        \"password\": None,\n",
    "    } for exchange in exchanges\n",
    "}\n",
    "\n",
    "ccxt_connector = CcxtConnector(exchanges_api_keys=exchanges_api_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build FeeModels\n",
    "\n",
    "fee_models = {}\n",
    "to_process = len(exchanges)\n",
    "processed = 0\n",
    "uniform_symbol_to_original_symbol = {}\n",
    "\n",
    "# Tickers format\n",
    "format1 = re.compile('^[a-zA-Z0-9_]+/[a-zA-Z0-9_]+$')\n",
    "format2 = re.compile('^\\.[a-zA-Z0-9_]+$')\n",
    "format3 = re.compile('^\\$[a-zA-Z0-9_]+/[a-zA-Z0-9_]+$')\n",
    "format4 = re.compile('^[a-zA-Z0-9_]+-[a-zA-Z0-9_]+$')\n",
    "format5 = re.compile('^[a-zA-Z0-9_]+FP$')\n",
    "format6 = re.compile('^[a-zA-Z0-9_]+_BQX$')\n",
    "format7 = re.compile('^[a-zA-Z0-9_]+_[0-9]{6}$')\n",
    "format8 = re.compile('^CMT_[a-zA-Z0-9_]+$')\n",
    "format9 = re.compile('^[a-zA-Z0-9_]+-[a-zA-Z0-9_]+-[0-9]{6}$')\n",
    "format10 = re.compile('^[a-zA-Z0-9_]+-[a-zA-Z0-9_]+-SWAP$')\n",
    "\n",
    "\n",
    "for exchange in exchanges:\n",
    "    print(f\"Building fee models for exchange {exchange}\")\n",
    "    exchange_to_lower = exchange.lower()\n",
    "    exchange_instance = ccxt_connector.get_exchange_instance(exchange_to_lower)\n",
    "\n",
    "    # first check if we can retrieve historical data\n",
    "    if \"fetchOHLCV\" not in exchange_instance.has or not exchange_instance.has[\"fetchOHLCV\"]:\n",
    "        processed += 1\n",
    "        print(f\"Progress: {processed} / {to_process}\")\n",
    "        continue\n",
    "    if \"fetchMarkets\" not in exchange_instance.has or not exchange_instance.has[\"fetchMarkets\"]:\n",
    "        processed += 1\n",
    "        print(f\"Progress: {processed} / {to_process}\")\n",
    "        continue\n",
    "    try:\n",
    "        market_info = exchange_instance.fetchMarkets()\n",
    "    except Exception as e:\n",
    "        processed += 1\n",
    "        print(f\"Progress: {processed} / {to_process}\")\n",
    "        continue\n",
    "    get_or_create_nested_dict(fee_models, exchange)\n",
    "\n",
    "\n",
    "    for symbol_info in market_info:\n",
    "        symbol = symbol_info[\"symbol\"]\n",
    "        symbol_before = symbol\n",
    "        if format1.match(symbol) is not None:\n",
    "            symbol = symbol.replace(\"/\", \"\").upper()\n",
    "        elif format2.match(symbol) is not None:\n",
    "            symbol = symbol.replace(\".\", \"\").upper()\n",
    "        elif format3.match(symbol) is not None:\n",
    "            symbol = symbol.replace(\"$\", \"\").upper()\n",
    "        elif format4.match(symbol) is not None:\n",
    "            symbol = symbol.replace(\"-\", \"\").upper()\n",
    "        elif format5.match(symbol) is not None:\n",
    "            symbol = symbol[:-2].upper()\n",
    "        elif format6.match(symbol) is not None:\n",
    "            symbol = symbol[:-4].upper()\n",
    "        elif format7.match(symbol) is not None:\n",
    "            symbol = symbol[:-7].upper()\n",
    "        elif format8.match(symbol) is not None:\n",
    "            symbol = symbol[:4].upper()\n",
    "        elif format9.match(symbol) is not None:\n",
    "            symbol = symbol.replace(\"-\", \"\")[:-6].upper()\n",
    "        elif format10.match(symbol) is not None:\n",
    "            symbol = symbol.replace(\"-\", \"\")[:-4].upper()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        get_or_create_nested_dict(fee_models, exchange, symbol)\n",
    "        # to simplify we just take the maximum of the 2 fees\n",
    "        # print(symbol_info)\n",
    "        if \"maker\" not in symbol_info and \"taker\" not in symbol_info:\n",
    "            continue\n",
    "        maker_fee = taker_fee = 0\n",
    "        if \"maker\" in symbol_info and symbol_info[\"maker\"] is not None:\n",
    "            maker_fee = float(symbol_info[\"maker\"])\n",
    "        if \"taker\" in symbol_info and symbol_info[\"taker\"] is not None:\n",
    "            taker_fee = float(symbol_info[\"taker\"])\n",
    "        fee = max(maker_fee, taker_fee)\n",
    "        fee_models[exchange][symbol] = PercentFeeModel(commission_pct=fee)\n",
    "        get_or_create_nested_dict(uniform_symbol_to_original_symbol, exchange)\n",
    "        uniform_symbol_to_original_symbol[exchange][symbol] = symbol_before\n",
    "    processed += 1\n",
    "    print(f\"Progress: {processed} / {to_process}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build exchange pairs\n",
    "seen = set()\n",
    "exchange_pairs = []\n",
    "filtered_exchanges = list(uniform_symbol_to_original_symbol.keys())\n",
    "for exchange1 in filtered_exchanges:\n",
    "    for exchange2 in filtered_exchanges:\n",
    "        if exchange2 in seen or exchange1 == exchange2:\n",
    "            continue\n",
    "        exchange_pairs.append((exchange1, exchange2))\n",
    "    seen.add(exchange1)\n",
    "\n",
    "LOOKBACK_PERIOD = timedelta(days=1)\n",
    "\n",
    "MINIMUM_TRANSACTIONS = 5\n",
    "MINIMUM_VOLUME_IN_CASH = 100\n",
    "STABLE_COINS = [\"USDT\", \"USDC\", \"BUSD\", \"DAI\", \"UST\", \"TUSD\", \"PAX\", \"HUSD\", \"USDN\", \"GUSD\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find common crypto pairs between exchange pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common pairs\n",
    "\n",
    "all_exchange_pairs = {}\n",
    "for exchange in filtered_exchanges:\n",
    "    all_exchange_pairs[exchange] = set()\n",
    "    \n",
    "common_pairs_dict = {}\n",
    "for exchange_pair in exchange_pairs:\n",
    "    exchange1 = exchange_pair[0]\n",
    "    exchange2 = exchange_pair[1]\n",
    "    get_or_create_nested_dict(common_pairs_dict, exchange1, exchange2)\n",
    "    \n",
    "    exchange1_tickers_list = list(uniform_symbol_to_original_symbol[exchange1].keys())\n",
    "    exchange2_tickers_list = list(uniform_symbol_to_original_symbol[exchange2].keys())\n",
    "    \n",
    "    common_pairs = np.intersect1d(exchange1_tickers_list, exchange2_tickers_list)\n",
    "    \n",
    "    def ends_with_stable_coin(pair: str):\n",
    "        for stable_coin in STABLE_COINS:\n",
    "            if pair.endswith(stable_coin):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Consider only stable coin pairs for now\n",
    "    common_pairs = [common_pair for common_pair in common_pairs if ends_with_stable_coin(common_pair)]\n",
    "\n",
    "    all_exchange_pairs[exchange1] |= set(common_pairs)\n",
    "    all_exchange_pairs[exchange2] |= set(common_pairs)\n",
    "\n",
    "    common_pairs_dict[exchange1][exchange2] = common_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exchange_pairs_filtered = {\n",
    "    exchange: pairs for exchange, pairs in all_exchange_pairs.items()\n",
    "    if len(pairs) != 0\n",
    "}\n",
    "filtered_exchanges = list(all_exchange_pairs_filtered.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_exchange_pairs_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_pairs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data for the last lookback period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK_PERIOD = timedelta(days=1)\n",
    "end = datetime.now(pytz.UTC)\n",
    "start = end - LOOKBACK_PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2021, 7, 30, 21, 3, 48, 25463, tzinfo=pytz.UTC)\n",
    "end = datetime(2021, 7, 31, 7, 3, 48, 25463, tzinfo=pytz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_combinations = []\n",
    "for exchange in filtered_exchanges:\n",
    "    all_pairs = all_exchange_pairs_filtered[exchange]\n",
    "    for pair in all_pairs:\n",
    "        download_combinations.append((exchange, pair))\n",
    "len_download_combinations = len(download_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_storage = InfluxDbStorage()\n",
    "historical_data_handler = CcxtHistoricalDataHandler(ccxt_connector)\n",
    "\n",
    "def download_data(download_combination):\n",
    "    exchange, pair = download_combination[0], download_combination[1]\n",
    "    print(f\"Downloading {exchange}-{pair}\")\n",
    "    original_pair = uniform_symbol_to_original_symbol[exchange][pair]\n",
    "    exchange_asset = Asset(symbol=original_pair, exchange=exchange)\n",
    "    historical_data_handler.save_ticker_data_in_db_storage(\n",
    "        exchange_asset, db_storage, start, end\n",
    "    )\n",
    "    print(f\"Finished downloading {exchange}-{pair}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "for _ in tqdm.tqdm(pool.imap_unordered(download_data, download_combinations), total=len_download_combinations):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for exchange_pair in exchange_pairs:\n",
    "    exchange1 = exchange_pair[0]\n",
    "    exchange2 = exchange_pair[1]\n",
    "\n",
    "    common_pairs = common_pairs_dict[exchange1][exchange2]\n",
    "    for common_pair in common_pairs:\n",
    "        combinations.append((exchange1, exchange2, common_pair))\n",
    "initial_budget = 2000\n",
    "empty_result = {\n",
    "    \"profit_pct\": 0,\n",
    "    \"cash_profit_pct\": 0,\n",
    "    \"coefficient of varition (abs)\": 1000000,\n",
    "    \"nb_errors\": 0,\n",
    "    \"errors_pct\": 0,\n",
    "    \"minimum number of transactions in both exchanges\": 0,\n",
    "    \"avg_volume_in_cash\": 0,\n",
    "    \"median_volume_in_cash\": 0\n",
    "}\n",
    "len_combinations = len(combinations)\n",
    "#combinations=[('aax', 'probit', 'REPUSDT'), ('aax', 'probit', 'REPUSDT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_common_pair_exchanges_pair(combination):\n",
    "    exchange1, exchange2, common_pair = combination[0], combination[1], combination[2]\n",
    "    exchanges = [exchange1, exchange2]\n",
    "    common_pair_key = f\"{exchange1}_{exchange2}_{common_pair}\"\n",
    "    print(f\"Checking arbitrage opportunities for {common_pair}\")\n",
    "    events = deque()\n",
    "    common_pair1 = uniform_symbol_to_original_symbol[exchange1][common_pair]\n",
    "    common_pair2 = uniform_symbol_to_original_symbol[exchange2][common_pair]\n",
    "    assets = [\n",
    "        Asset(symbol=common_pair1, exchange=exchange1),\n",
    "        Asset(symbol=common_pair2, exchange=exchange2)\n",
    "    ]\n",
    "    assets_dict = {asset.exchange: asset for asset in assets}\n",
    "\n",
    "    # load data\n",
    "    #feed: Feed = CsvFeed(\n",
    "    #    {\n",
    "    #        asset: f\"backtests/crypto_arbitrage/data/{common_pair.lower()}_{asset.exchange.lower()}.csv\"\n",
    "    #        for asset in assets\n",
    "    #    },\n",
    "    #    events,\n",
    "    #)\n",
    "\n",
    "    feed: Feed = ExternalStorageFeed(\n",
    "        assets = assets,\n",
    "        events = events,\n",
    "        time_unit = timedelta(minutes=1),\n",
    "        start = start,\n",
    "        end = end,\n",
    "        db_storage = db_storage,\n",
    "        file_storage = None,\n",
    "        market_cal = None,\n",
    "    )\n",
    "\n",
    "    # Check wether data is empty or not\n",
    "    exchange1_candle_dataframe = feed.candle_dataframes[\n",
    "        assets_dict[exchange1]\n",
    "    ]\n",
    "    if exchange1_candle_dataframe.empty:\n",
    "        print(f\"{common_pair_key} data is empty for exchange1_candle_dataframe so it is skipped.\")\n",
    "        return empty_result\n",
    "\n",
    "    exchange2_candle_dataframe = feed.candle_dataframes[\n",
    "        assets_dict[exchange2]\n",
    "    ]\n",
    "    #print(exchange2_candle_dataframe)\n",
    "    if exchange2_candle_dataframe.empty:\n",
    "        print(f\"{common_pair_key} data is empty for exchange2_candle_dataframe so it is skipped.\")\n",
    "        return empty_result\n",
    "\n",
    "    # don't process the pair if the volume is low\n",
    "    exchange1_prices = pd.to_numeric(exchange1_candle_dataframe[\"close\"])\n",
    "    exchange1_volumes = pd.to_numeric(exchange1_candle_dataframe[\"volume\"])\n",
    "    exchange1_avg_price = exchange1_prices.mean()\n",
    "    exchange1_median_price = exchange1_prices.median()\n",
    "    exchange1_avg_volume = exchange1_volumes.mean()\n",
    "    exchange1_median_volume = exchange1_volumes.median()\n",
    "\n",
    "    exchange2_prices = pd.to_numeric(exchange2_candle_dataframe[\"close\"])\n",
    "    exchange2_volumes = pd.to_numeric(exchange2_candle_dataframe[\"volume\"])\n",
    "    exchange2_avg_price = exchange2_prices.mean()\n",
    "    exchange2_median_price = exchange2_prices.median()\n",
    "    exchange2_avg_volume = exchange2_volumes.mean()\n",
    "    exchange2_median_volume = exchange2_volumes.median()\n",
    "\n",
    "    avg_price = min(exchange1_avg_price, exchange2_avg_price)\n",
    "    median_price = min(exchange1_median_price, exchange2_median_price)\n",
    "    avg_volume = min(exchange1_avg_volume, exchange2_avg_volume)\n",
    "    median_volume = min(exchange1_median_volume, exchange2_median_volume)\n",
    "\n",
    "    avg_volume_in_cash = avg_volume * avg_price\n",
    "    median_volume_in_cash = median_volume * median_price\n",
    "\n",
    "    # if volume_in_cash == 0.0:\n",
    "    #    processed += 1\n",
    "    #    print(f\"{common_pair_key} volume in cash {volume_in_cash} is lower than the minimum volume in cash required {MINIMUM_VOLUME_IN_CASH} so it is skipped.\")\n",
    "    #    print(f\"Current rank: {profit_rank}\")\n",
    "    #    print(f\"Progress: {processed} / {to_process}\")\n",
    "    #    continue\n",
    "\n",
    "    # Create brokers for exchanges, put a big amount of cash and a big amount of shares to allow all two\n",
    "    # ways transactions\n",
    "    strategies = {ArbitrageStrategy: [{\"margin_factor\": 2}]}\n",
    "\n",
    "    clock = SimulatedClock()\n",
    "    initial_funds = initial_budget / 2\n",
    "    # print(f\"initial_funds = {initial_funds}\")\n",
    "    # Create brokers with a big amount of money\n",
    "    exchange1_broker = SimulatedBroker(\n",
    "        clock,\n",
    "        events,\n",
    "        initial_funds=initial_funds,\n",
    "        fee_model=fee_models[exchange1][common_pair],\n",
    "        exchange=exchange1,\n",
    "    )\n",
    "    exchange1_broker.subscribe_funds_to_portfolio(initial_funds)\n",
    "    exchange1_first_candle = exchange1_candle_dataframe.get_candle(0)\n",
    "    exchange1_broker.update_price(exchange1_first_candle)\n",
    "\n",
    "    exchange2_broker = SimulatedBroker(\n",
    "        clock,\n",
    "        events,\n",
    "        initial_funds=initial_funds,\n",
    "        fee_model=fee_models[exchange2][common_pair],\n",
    "        exchange=exchange2,\n",
    "    )\n",
    "    # exchange2_broker.subscribe_funds_to_portfolio(initial_funds)\n",
    "    exchange2_first_candle = exchange2_candle_dataframe.get_candle(0)\n",
    "    exchange2_broker.update_price(exchange2_first_candle)\n",
    "    max_size_exchange1 = exchange1_broker.max_entry_order_size(\n",
    "        assets_dict[exchange1], Direction.LONG, initial_funds\n",
    "    )\n",
    "    max_size_exchange2 = exchange2_broker.max_entry_order_size(\n",
    "        assets_dict[exchange2], Direction.LONG, initial_funds\n",
    "    )\n",
    "    initial_size = max_size_exchange2\n",
    "\n",
    "    # exchange 2\n",
    "    candle = Candle(\n",
    "        asset=assets_dict[exchange2], open=0, high=0, low=0, close=0, volume=0\n",
    "    )\n",
    "    exchange2_broker.update_price(candle)\n",
    "    order = Order(\n",
    "        asset=assets_dict[exchange2],\n",
    "        action=Action.BUY,\n",
    "        direction=Direction.LONG,\n",
    "        size=initial_size,\n",
    "        signal_id=\"0\",\n",
    "        limit=None,\n",
    "        stop=None,\n",
    "        target=None,\n",
    "        stop_pct=None,\n",
    "        type=OrderType.MARKET,\n",
    "        clock=clock,\n",
    "        time_in_force=timedelta(minutes=5),\n",
    "    )\n",
    "    exchange2_broker.execute_market_order(order)\n",
    "\n",
    "    # prepare event loop parameters\n",
    "    broker_manager = BrokerManager(\n",
    "        brokers={\n",
    "            exchange1: exchange1_broker,\n",
    "            exchange2: exchange2_broker,\n",
    "        },\n",
    "        clock=clock,\n",
    "    )\n",
    "    position_sizer = PositionSizer(broker_manager=broker_manager, integer_size=False)\n",
    "    order_creator = OrderCreator(broker_manager=broker_manager)\n",
    "    order_manager = OrderManager(\n",
    "        events=events,\n",
    "        broker_manager=broker_manager,\n",
    "        position_sizer=position_sizer,\n",
    "        order_creator=order_creator,\n",
    "    )\n",
    "    indicators_manager = IndicatorsManager(\n",
    "        preload=True, initial_data=feed.candles\n",
    "    )\n",
    "    event_loop = EventLoop(\n",
    "        events=events,\n",
    "        assets=assets,\n",
    "        feed=feed,\n",
    "        order_manager=order_manager,\n",
    "        strategies_parameters=strategies,\n",
    "        indicators_manager=indicators_manager,\n",
    "        close_at_end_of_day=False,\n",
    "        close_at_end_of_data=False\n",
    "    )\n",
    "\n",
    "    # get initial state of portfolio for stats computation total_market_value\n",
    "    exchange1_broker.update_price(exchange1_first_candle)\n",
    "    exchange2_broker.update_price(exchange2_first_candle)\n",
    "    initial_market_values = sum([broker_manager.get_broker(exchange).get_portfolio_total_market_value() for exchange in exchanges])\n",
    "    initial_cash_balances = sum([broker_manager.get_broker(exchange).get_portfolio_cash_balance() for exchange in exchanges])\n",
    "    initial_equities = initial_cash_balances + initial_market_values\n",
    "\n",
    "    # print(f\"initial_market_values = {initial_market_values}\")\n",
    "    # print(f\"initial_cash_balances = {initial_cash_balances}\")\n",
    "    # print(f\"initial_equities = {initial_equities}\")\n",
    "\n",
    "    event_loop.loop()\n",
    "    \n",
    "    exchange1_history = exchange1_broker.portfolio.history\n",
    "    # print([str(portfolio_event) for portfolio_event in exchange1_history])\n",
    "    exchange1_transactions = [portfolio_event for portfolio_event in exchange1_history if portfolio_event.type == \"symbol_transaction\"]\n",
    "    # remove first transaction, which is to add securities in the broker\n",
    "    exchange1_transactions = exchange1_transactions[1:]\n",
    "\n",
    "    exchange2_history = exchange2_broker.portfolio.history\n",
    "    # print([str(portfolio_event) for portfolio_event in exchange2_history])\n",
    "    exchange2_transactions = [portfolio_event for portfolio_event in exchange2_history if portfolio_event.type == \"symbol_transaction\"]\n",
    "    # remove first transaction, which is to add securities in the broker\n",
    "    exchange2_transactions = exchange2_transactions[1:]\n",
    "\n",
    "    # exchange1_transactions_timestamps = np.array([transaction.timestamp for transaction in exchange1_transactions], dtype=datetime)\n",
    "    # exchange2_transactions_timestamps = np.array([transaction.timestamp for transaction in exchange2_transactions], dtype=datetime)\n",
    "    # common_timestamps = np.intersect1d(exchange1_transactions_timestamps, exchange2_transactions_timestamps)\n",
    "\n",
    "    # filter timestamps\n",
    "    # exchange1_transactions = [transaction for transaction in exchange1_transactions if transaction.timestamp in common_timestamps]\n",
    "    # exchange2_transactions = [transaction for transaction in exchange2_transactions if transaction.timestamp in common_timestamps]\n",
    "\n",
    "    nb_transactions1 = len(exchange1_transactions)\n",
    "    nb_transactions2 = len(exchange2_transactions)\n",
    "    min_nb_transactions = min(nb_transactions1, nb_transactions2)      \n",
    "    #if min_nb_transactions < MINIMUM_TRANSACTIONS:\n",
    "    #    processed += 1\n",
    "    #    print(f\"{common_pair_key} has only {min_nb_transactions} transactions which is less than the minimum required number of transactions {MINIMUM_TRANSACTIONS} so it is skipped.\")\n",
    "    #    print(f\"Current rank: {profit_rank}\")\n",
    "    #    print(f\"Progress: {processed} / {to_process}\")\n",
    "    #    continue\n",
    "\n",
    "    # find missed opportunities\n",
    "\n",
    "    \"\"\"\n",
    "    When an arbitrage opportunity is found, we submit 2 orders to the brokers of the 2 exchanges.\n",
    "    If one of the order is not executed because of for example not enough cash or, whathever reason,\n",
    "    we call it an \"error\". The less errors you have, the better it is for ensuring the stability of the strategy\n",
    "    \"\"\"\n",
    "    nb_errors = 0\n",
    "    transaction_profits = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    while i < nb_transactions1 and j < nb_transactions2:\n",
    "        transaction1 = exchange1_transactions[i]\n",
    "        transaction2 = exchange2_transactions[j]\n",
    "        if transaction1.timestamp == transaction2.timestamp:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif transaction1.timestamp < transaction2.timestamp:\n",
    "            i += 1\n",
    "            nb_errors += 1\n",
    "        else: # transaction1.timestamp > transaction2.timestamp\n",
    "            j += 1\n",
    "            nb_errors += 1\n",
    "        if transaction1.action == Action.BUY:\n",
    "            transaction_profit = transaction2.credit - transaction1.debit\n",
    "        else:\n",
    "            transaction_profit = transaction1.credit - transaction2.debit\n",
    "        transaction_profits.append(transaction_profit)\n",
    "\n",
    "    #if nb_errors > min_nb_transactions:\n",
    "    #    print(f\"{common_pair_key} nb errors is greater than number of transactions {min_nb_transactions} transactions so it is skipped.\")\n",
    "    #    continue\n",
    "\n",
    "    volume_in_cash_result = {\n",
    "        \"profit_pct\": 0,\n",
    "        \"cash_profit_pct\": 0,\n",
    "        \"coefficient of varition (abs)\": 1000000,\n",
    "        \"nb_errors\": 0,\n",
    "        \"errors_pct\": 0,\n",
    "        \"minimum number of transactions in both exchanges\": min_nb_transactions,\n",
    "        \"avg_volume_in_cash\": avg_volume_in_cash,\n",
    "        \"median_volume_in_cash\": median_volume_in_cash\n",
    "    }\n",
    "    if len(transaction_profits) == 0:\n",
    "        print(f\"{common_pair_key} transaction_profits is zero so it is skipped.\")\n",
    "        return volume_in_cash_result\n",
    "\n",
    "    errors_pct = 0\n",
    "    max_nb_transactions = max(nb_transactions1, nb_transactions2)\n",
    "    if max_nb_transactions != 0:\n",
    "        errors_pct = nb_errors / max_nb_transactions * 100\n",
    "    cash_profit = sum(transaction_profits)\n",
    "\n",
    "    # let's find the coefficient of variation to filter\n",
    "    cv = lambda x: np.std(x, ddof=1) / np.mean(x) * 100 \n",
    "    coefficient_of_variation = cv(transaction_profits)\n",
    "\n",
    "    final_market_values = sum([broker_manager.get_broker(exchange).get_portfolio_total_market_value() for exchange in exchanges])\n",
    "    final_cash_balances = sum([broker_manager.get_broker(exchange).get_portfolio_cash_balance() for exchange in exchanges])\n",
    "    final_equities = final_market_values + final_cash_balances\n",
    "\n",
    "    # print(f\"final_market_values = {final_market_values}\")\n",
    "    # print(f\"final_cash_balances = {final_cash_balances}\")\n",
    "    # print(f\"final_equities = {final_equities}\")\n",
    "\n",
    "    profit = final_equities - initial_equities\n",
    "\n",
    "    profit_pct = profit / initial_equities * 100\n",
    "\n",
    "    cash_profit_pct = cash_profit / initial_cash_balances * 100\n",
    "\n",
    "    return {\n",
    "        \"profit_pct\": profit_pct,\n",
    "        \"cash_profit_pct\": cash_profit_pct,\n",
    "        \"coefficient of varition (abs)\": abs(coefficient_of_variation),\n",
    "        \"nb_errors\": nb_errors,\n",
    "        \"errors_pct\": errors_pct,\n",
    "        \"minimum number of transactions in both exchanges\": min_nb_transactions,\n",
    "        \"avg_volume_in_cash\": avg_volume_in_cash,\n",
    "        \"median_volume_in_cash\": median_volume_in_cash\n",
    "    }\n",
    "\n",
    "    # exchange1_broker.portfolio.history_to_df().to_csv(f\"backtests/crypto_arbitrage/data/transactions/{common_pair.lower()}_{exchange1.lower()}_transactions.csv\")\n",
    "    # exchange2_broker.portfolio.history_to_df().to_csv(f\"backtests/crypto_arbitrage/data/transactions/{common_pair.lower()}_{exchange2.lower()}_transactions.csv\")\n",
    "\n",
    "    # Order by number of errors\n",
    "    # profit_rank = {k: v for k, v in sorted(profit_pct_dict.items(), key=lambda item: item[1][\"coefficient of varition (abs)\"], reverse=False)}\n",
    "    # print(f\"Current rank: {profit_rank}\")\n",
    "    # best_results_df = pd.DataFrame.from_dict(profit_rank, orient=\"index\")\n",
    "    # with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    #    print(best_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "results = list(\n",
    "    tqdm.tqdm(\n",
    "        pool.imap_unordered(\n",
    "            process_common_pair_exchanges_pair,\n",
    "            combinations\n",
    "        ),\n",
    "        total=len(combinations)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    f\"{combination[0]}-{combination[1]}-{combination[2]}\": results[index]\n",
    "    for index, combination in enumerate(combinations)\n",
    "}\n",
    "best_results_df = pd.DataFrame.from_dict(results_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df.to_csv(\"final_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    \"profit_pct\": float,\n",
    "    \"cash_profit_pct\": float,\n",
    "    \"coefficient of varition (abs)\": float,\n",
    "    \"nb_errors\": int,\n",
    "    \"errors_pct\": float,\n",
    "    \"minimum number of transactions in both exchanges\": int,\n",
    "    \"avg_volume_in_cash\": float,\n",
    "    \"median_volume_in_cash\": float\n",
    "}\n",
    "best_results_df = pd.read_csv(\"final_results.csv\", dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_results_df.columns)\n",
    "print(len(best_results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (best_results_df[\"profit_pct\"] > 0) & \\\n",
    "       (best_results_df[\"cash_profit_pct\"] > 0)\n",
    "best_results_df = best_results_df[mask].dropna()\n",
    "len(best_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df = best_results_df.sort_values(\"profit_pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights =  {\n",
    "    \"profit_pct\": 5,\n",
    "    \"cash_profit_pct\": 3,\n",
    "    \"coefficient of varition (abs)\": 2,\n",
    "    \"nb_errors\": 0,\n",
    "    \"errors_pct\": 2,\n",
    "    \"minimum number of transactions in both exchanges\": 3,\n",
    "    \"avg_volume_in_cash\": 0,\n",
    "    \"median_volume_in_cash\": 0\n",
    "}\n",
    "import math\n",
    "\n",
    "def get_score(row):\n",
    "    score = 0\n",
    "    for metric, weight in weights.items():\n",
    "        score += math.exp(weight) * row[metric]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_results_df[\"score\"] = best_results_df.apply(get_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_df.sort_values(\"profit_pct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
